{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Web Scraping For The SCSDay App"},{"metadata":{},"cell_type":"markdown","source":"This repo contains a project for an app that displays the schedule for the current day for the Smithtown High Schools"},{"metadata":{},"cell_type":"markdown","source":"This app runs by using the beautifulsoup4 python package to web scrape the school buletin"},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install bs4\n! pip install requests\n\nfrom bs4 import BeautifulSoup\nimport requests","execution_count":1,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: bs4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from bs4) (4.9.1)\nRequirement already satisfied: soupsieve>1.2 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from beautifulsoup4->bs4) (2.0.1)\nRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.6/site-packages (2.24.0)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests) (1.25.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from requests) (3.0.4)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creates the url necessary to generating the HTML request\n\nurl = 'http://example.webscraping.com/'","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parses the incomming HTML request to become readable for the bs4 package\n\nhtml_text = requests.get(url).text\nsoup = BeautifulSoup(html_text, 'html.parser')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finds the specific HTML element \n\nbase = soup.find(\"div\", { \"class\" : \"page-header\" })\nelement = base.find('h1')\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prints out the desired outcome while also clearing out the unwanted HTML Tags\n\nprint(str(element)[4:].split('<')[0])","execution_count":5,"outputs":[{"output_type":"stream","text":"\n                    Example web scraping website\n                    \n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}